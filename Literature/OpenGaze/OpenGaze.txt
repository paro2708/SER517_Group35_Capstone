OpenGaze model is an open-source implementation of a smartphone-based gaze tracker using TensorFlow and PyTorch, inspired by a proprietary Google model. It achieved accuracy comparable to Google’s model on the MIT GazeCapture [3] dataset without requiring specialized hardware. This demonstrated the potential to enable largescale eye-tracking research and applications in accessibility, healthcare, etc. The paper builds off the proprietary work introduced in the study by Valliappan et al. (2020).It presents a comprehensive review of datasets and methodologies that have been pivotal in refining the accuracy of gaze predictions. This paper delves into the technical details of the OpenGazeModel’s architecture and its performance across various datasets, highlighting the significant improvements over existing models. It also discusses the broader implications of these advancements for developing more intuitive and natural user interfaces. This Google paper proposed a machinelearning method for smartphone-based eye tracking but did not release code or models. The paper aimed to replicate eye movement patterns during reading, image viewing, and other tasks. Wherein, the paper presented a comprehensive evaluation of appearance-based gaze estimation model-based methods and commercial eye trackers. It acknowledges the foundational work of researchers who have contributed to enhancing the accuracy and robustness of gaze tracking under varied environmental conditions and across different user populations. This paper [10] situates the OpenGaze toolkit within the continuum of research, arguing for its potential to democratize gaze-based HCI through ease of integration and adaptability to diverse application needs. The paper discussed the implication of the results for major gazed-based Human-Computer Interaction (HCI) applications like explicit eye input, attentive UIs, gaze-based user modeling, and passive eye monitoring. It provides easy-to-use APIs and implementation of the full pipeline for non-experts. Paper [9] demonstrates the performance of the PyTorch models, detailing their predictive accuracy across various datasets and comparing them to Google’s benchmarks. It includes an in-depth analysis of the application of Support Vector Regression (SVR) for personalization, showing its impact on improving gaze tracking accuracy. This section demonstrates the potential of SVR for enhancing model precision, with detailed comparisons of error rates before and after SVR application, across different devices and conditions. SVR was applied to methods that enhanced performance by around 13% with MIT Split whereas in 20% enhancement in performance with Google Split. The results obtained by an upgraded model signify the positive impact of the SVR technique. Additionally, it explores the use of affine transformations for further accuracy improvements, indicating the nuanced balance between model generalization and individualized refinement. The key challenges are limited public data, model efficiency constraints, and generalization. Paper addresses the quest for better accuracy and reliability in gaze estimationtechnologies, especially in outdoor settings with varied lighting conditions and user environments.