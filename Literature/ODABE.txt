Salvalaio and Ramos introduced ODABE (Online Deep Appearance-Based Eye-Tracking) to address the limitations of existing eye-tracking models in adapting to different contexts rapidly. They identified a gap in the literature where current methods could not generalize effectively across diverse combinations of users, environments, and devices. To overcome this challenge, they proposed ODABE, which integrates online transfer learning into appearance-based eye-tracking models. ODABE combines pre-training on established datasets like MPIIGaze with online fine-tuning using a new dataset collected during user interactions. During pre-training, a baseline model is trained using MPIIGaze, and then, when new contexts arise, ODABE leverages online transfer learning to adjust the model rapidly to the specific context. This approach enables the model to self-adapt and improve its performance in real-time, without the need for extensive retraining or manual adjustments. Experimental evaluations conducted by Salvalaio and Ramos demonstrated the effectiveness of ODABE in handling diverse eye-tracking contexts. Compared to previous methods, ODABE showed a significant reduction in prediction error, with an average decrease of 50.95\% across tested cases. These results highlight the efficacy of ODABE in achieving robust and adaptable eye-tracking performance in various scenarios. In summary, ODABE represents a novel approach to appearance-based eye-tracking, addressing the challenge of context adaptation through online transfer learning. The experimental findings underscore the effectiveness of ODABE in improving eye-tracking accuracy across different user, environment, and device combinations.